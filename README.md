<p align="center">
  <img src="img/banner.png" alt="OllaForge Banner" width="100%">
</p>

<h1 align="center">OllaForge ğŸ”¥</h1>

<p align="center">
  <strong>AI-Powered Dataset Generator for LLM Fine-tuning</strong>
</p>

<p align="center">
  <a href="#features">Features</a> â€¢
  <a href="#quick-start">Quick Start</a> â€¢
  <a href="#usage">Usage</a> â€¢
  <a href="#dataset-formats">Formats</a> â€¢
  <a href="#performance">Performance</a> â€¢
  <a href="#contributing">Contributing</a>
</p>

<p align="center">
  <a href="README.md">English</a> | <a href="README_zh-TW.md">ç¹é«”ä¸­æ–‡</a>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/python-3.9+-blue.svg" alt="Python 3.9+">
  <img src="https://img.shields.io/badge/license-MIT-green.svg" alt="License: MIT">
  <img src="https://img.shields.io/badge/ollama-local-orange.svg" alt="Ollama">
  <img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg" alt="PRs Welcome">
</p>

---

**OllaForge** is a high-performance CLI tool that leverages local Ollama models to generate training datasets for LLM fine-tuning. With structured JSON output, concurrent batch processing, and built-in quality control for Traditional Chinese, it's optimized for both quality and speed.

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| ğŸ¯ **Natural Language Topics** | Describe your dataset needs in plain language |
| ğŸ¤– **Any Ollama Model** | Works with Llama 3, Mistral, Qwen, DeepSeek, Gemma, and more |
| ğŸ“Š **4 Dataset Formats** | SFT, Pre-training, Conversation (ShareGPT), DPO |
| ğŸŒ **Multi-language** | English and Traditional Chinese (Taiwan) with QC |
| âš¡ **High Performance** | Structured output + concurrent batching |
| ğŸ” **Quality Control** | BERT-based filtering for Taiwan Chinese terminology |
| ğŸ¨ **Beautiful CLI** | Interactive wizard with Rich-powered UI |
| ğŸ”„ **HuggingFace Ready** | Compatible with HuggingFace & LLaMA-Factory |

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9+
- [Ollama](https://ollama.ai/) installed and running

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/ollaforge.git
cd ollaforge

# Install (basic)
pip install -e .

# Install with QC support for Traditional Chinese
pip install -e ".[qc]"

# Install with dev tools
pip install -e ".[dev]"
```

### Your First Dataset

```bash
# Interactive mode (recommended for beginners)
ollaforge -i

# Or generate directly
ollaforge "Python programming tutorials" --count 100 --output python_sft.jsonl

# Traditional Chinese conversation dataset
ollaforge "å’–å•¡é»é¤å°è©±" --type sft_conv --lang zh-tw --count 100
```

## ğŸ“– Usage

### Command Line

```bash
ollaforge <topic> [options]
```

| Option | Short | Default | Description |
|--------|-------|---------|-------------|
| `--count` | `-c` | 10 | Number of entries (1-10,000) |
| `--model` | `-m` | llama3.2 | Ollama model name |
| `--output` | `-o` | dataset.jsonl | Output filename |
| `--type` | `-t` | sft | Format: `sft`, `pretrain`, `sft_conv`, `dpo` |
| `--lang` | `-l` | en | Language: `en`, `zh-tw` |
| `--concurrency` | `-j` | 5 | Parallel requests (1-20) |
| `--qc/--no-qc` | | --qc | Taiwan Chinese QC filter |
| `--qc-confidence` | | 0.9 | QC threshold (0.0-1.0) |
| `--interactive` | `-i` | | Launch wizard mode |

### Examples

```bash
# SFT instruction-following data
ollaforge "customer service conversations" --count 500 --type sft

# Pre-training corpus
ollaforge "machine learning concepts" --type pretrain --count 1000

# Multi-turn conversations (ShareGPT format)
ollaforge "technical support dialogues" --type sft_conv -o conversations.jsonl

# DPO preference pairs
ollaforge "code review feedback" --type dpo --count 200

# Traditional Chinese with QC
ollaforge "å®¢æœå°è©±ç¯„ä¾‹" --lang zh-tw --count 100 --qc-confidence 0.85

# Use specific model with high concurrency
ollaforge "medical Q&A" --model qwen2.5:14b --count 500 -j 10
```

## ğŸ“‹ Dataset Formats

### SFT (Alpaca Format)
```json
{"instruction": "Explain recursion", "input": "", "output": "Recursion is..."}
```

### Pre-training
```json
{"text": "Machine learning is a subset of artificial intelligence..."}
```

### SFT Conversation (ShareGPT/ChatML)
```json
{
  "conversations": [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "How do I reverse a string?"},
    {"role": "assistant", "content": "Use slicing: `s[::-1]`"}
  ]
}
```

### DPO (Preference Pairs)
```json
{"prompt": "Write factorial", "chosen": "def factorial(n)...", "rejected": "def f(n):..."}
```

## âš¡ Performance Optimizations

OllaForge is optimized for Mac (Apple Silicon) and local LLM inference:

| Optimization | Benefit |
|--------------|---------|
| **Structured JSON Output** | 0% format errors via Ollama's schema enforcement |
| **Small Batch Size (5)** | Reduces attention decay, improves quality |
| **Concurrent Requests** | Up to 10 parallel batch requests |
| **BERT on CPU** | Keeps GPU/MPS free for LLM generation |
| **Funnel Architecture** | Over-request â†’ Filter â†’ Keep valid entries |

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Prompt    â”‚â”€â”€â”€â”€â–¶â”‚  Ollama API  â”‚â”€â”€â”€â”€â–¶â”‚   JSON      â”‚
â”‚  Engineeringâ”‚     â”‚  (Parallel)  â”‚     â”‚   Schema    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â–¼
                    â”‚   QC Filter  â”‚â—€â”€â”€â”€â”€â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  (CPU BERT)  â”‚     â”‚  Processor  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   JSONL     â”‚
                    â”‚   Output    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ” Traditional Chinese QC

When using `--lang zh-tw`, OllaForge automatically filters Mainland Chinese expressions:

| âŒ Filtered | âœ… Accepted |
|-------------|-------------|
| è»Ÿä»¶ | è»Ÿé«” |
| è¦–é » | å½±ç‰‡ |
| ç¨‹åº | ç¨‹å¼ |
| ç¶²çµ¡ | ç¶²è·¯ |
| ä¿¡æ¯ | è³‡è¨Š |

```bash
# Enable QC (default)
ollaforge "å°è©±" --lang zh-tw --qc

# Stricter threshold
ollaforge "å°è©±" --lang zh-tw --qc-confidence 0.95

# Disable QC
ollaforge "å°è©±" --lang zh-tw --no-qc
```

## ğŸ¤– Recommended Models

| Model | Best For |
|-------|----------|
| `llama3.2` | General purpose (default) |
| `qwen2.5:14b` | Multilingual, Chinese |
| `deepseek-r1:14b` | Reasoning tasks |
| `gemma2:9b` | Efficient, single GPU |
| `mistral:7b` | Fast inference |

## ğŸ—ï¸ Project Structure

```
ollaforge/
â”œâ”€â”€ ollaforge/
â”‚   â”œâ”€â”€ __init__.py      # Package exports
â”‚   â”œâ”€â”€ cli.py           # CLI implementation
â”‚   â”œâ”€â”€ client.py        # Ollama API + JSON schema
â”‚   â”œâ”€â”€ processor.py     # Response parsing
â”‚   â”œâ”€â”€ models.py        # Pydantic models
â”‚   â”œâ”€â”€ qc.py            # Taiwan Chinese QC
â”‚   â”œâ”€â”€ progress.py      # Progress tracking
â”‚   â””â”€â”€ file_manager.py  # File I/O
â”œâ”€â”€ tests/               # Test suite
â”œâ”€â”€ pyproject.toml       # Project config
â””â”€â”€ Makefile             # Dev commands
```

## ğŸ§ª Development

```bash
# Install dev dependencies
make install-dev

# Run tests
make test

# Lint & format
make lint
make format

# Type check
make typecheck

# All checks
make check
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing`)
5. Open a Pull Request

See [CONTRIBUTING.md](CONTRIBUTING.md) for details.

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

## ğŸ™ Acknowledgments

- [Ollama](https://ollama.ai/) - Local LLM inference
- [Rich](https://github.com/Textualize/rich) - Beautiful terminal UI
- [Typer](https://typer.tiangolo.com/) - CLI framework
- [Pydantic](https://pydantic.dev/) - Data validation

---

<p align="center">
  Made with â¤ï¸ by the OllaForge Team
</p>
